---
title: Exploratory Analysis of Factors Associated with Cancer Mortality in the National Health and Nutrition Examination Survey Dataset
author:
- Martin Skarzynski
- Prof. Elizabeth Platz
institute: Johns Hopkins School of Public Health
date: "`r Sys.Date()`"
output:
  word_document:
    reference_docx: style.docx
bibliography: bibliography.bib
csl: bib/biomed-central.csl
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = TRUE, warning = FALSE, message = FALSE)
```

```{r libraries, include=FALSE}
library(knitr)
library(readr)
```

## Abstract

**Context:** Large epidemiologic cohort studies, such as the National Health and Nutrition Examination Survey (NHANES), collect copious high-dimensional data that allow for examination of multiple exposures in relation to a given outcome.

**Objective:** To explore the exposures measured in the Third National Health and Nutrition Examination Survey (NHANES III) dataset in search of factors associated with cancer mortality data obtained from the National Death Index (NDI) and to assess methods for lethal cancer risk prediction model variable selection.

**Design, Setting and Participants:** NHANES III collected data on 33,994 participants aged 2 months and older from 1988 to 1994 in the United States. The data, which include Interview, Medical Examination, and Laboratory components, were collected and linked with Mortality data from NDI death certificate records by the National Center for Health Statistics (NCHS) of the Centers for Disease Control and Prevention (CDC). From the initial pool of participants, we selected 16404 adult participants that were cancer-free at baseline and that had no missing values for follow-up time since interview, NDI mortality, primary sampling units (PSU), stratification, and sampling weight variables.

**Exposures:** The initial publicly available dataset contained 3544 exposures from the Interview, Medical Examination, Laboratory, and Mortality components. After removing variables that were non-numeric, missing any values, only had one unique value, or had correlation to another variable greater than 0.9, we obtained the final set of 243 exposures. The analysis described herein did not involve multiple imputation nor utilize the NHANES III Multiply Imputed Data Set.

**Main Outcome Measure:** Among the 16404 patients, there were 964 cancer deaths and 280891 total years of follow-up since the initial Interview data were collected. The cancer deaths and follow-up time were used as the outcome (survival) in Cox proportional hazards regression analysis.

**Results:** We fit thousands of Cox proportional hazards models with and without ridge penalties to randomly selected subsets of up to 50 variables and divided the models into 4 groups based on their Akaike Information Criterion (AIC) and concordance values. We analyzed the descriptions of NHANES variables provided by NCHS and selected 3 variables (age, sex and ethnicity) to include in all future models. We then compared variables that appeared most frequently in the Cox models with high significance (p < 10^-10^) and selected 5 high-frequency, highly significant variables that we used to train a new group of models with fewer randomized variables. These models outperformed the fully randomized models in terms of concordance while displaying the roughly same range of AIC values.

**Conclusions:** The work described here constitutes an exploratory analysis of the NHANES III dataset that employs an iterative strategy to generation of cancer risk prediction models. In this approach, a large number of models are generated randomly to inform variable selection and guide training of models in future iterations. In addition to providing insight into cancer risk factors measured in the NHANES III dataset we hope to develop a general methodology that can be applied to large, high-dimensional cohort study data.

## Introduction

Cancer susceptibility is influenced by modifiable and non-modifiable factors. Modifiable cancer risk factors include Body Mass Index (BMI) and cigarette use, whereas the non-modifiable factors include Single Nucleotide Polymorphisms (SNPs) and family history of disease. According to a 2018 study by Islami and colleagues [@Islami_2018], modifiable risk factors are responsible for 42% of all cancer cases and 45% of all cancer deaths. This finding suggests that cancer prevention strategies that target modifiable risk factors have the potential to almost halve cancer incidence and mortality in the United States. A near two-fold reduction in cancer cases and deaths may seem far-fetched, but cancer incidence and mortality in United Status have been declining by ~1.5% every year from 2009-2014 and 2001-2015, respectively [@Siegel_2018]. Taken together, these data indicate that while tremendous progress has been made, there is still great potential for cancer prevention approaches to decrease cancer incidence and mortality.

The scale of cancer burden in the United States is staggering. Siegel and colleagues estimate that in 2018 there will be 1.7 million newly diagnosed cancer cases and roughly 600 thousand cancer deaths [@Siegel_2018]. Cancer risk prediction models can help policymakers and cancer prevention practitioners develop more effective interventions and to channel limited resources towards people at the greatest risk. To achieve the best performance, cancer risk prediction models must include both modifiable and non-modifiable risk factors. In 2016, Maas and colleagues [@Maas_2016] demonstrated that cancer risk prediction models based on known epidemiologic risk factors can be improved when genetic information such as SNPs are included in the models. Importantly, the combined model provided better risk stratification than the models containing only epidemiologic risk factors or only genetic variables. The 2016 Maas study [@Maas_2016] focused on breast cancer, but the methodology can be applied to other cancers.

The challenge of cancer risk prediction is complex and will require cancer-type specific strategies that integrate multiple types of data and explore various modeling methods. In addition to deepening our understanding of known cancer risk factors, it is imperative to identify new factors that may only be meaningful in the larger context of contributors to cancer risk. This larger context includes the collection of genetic inheritance, called the genome, and the myriad exposures that individuals experience during their lives, known as the exposome [@Wild_2005].

Some genetic factors and environmental exposures may be very strongly linked to cancer. Examples of well-described genetic and environmental cancer risk factors include TP53 gene mutation in Li-Fraumeni Syndrome and asbestos inhalation in mesothelioma, respectively. One of the strongest cancer risk factors is cigarette smoking. In fact, smoking was the strongest modifiable risk factor in the 2018 study by Islami and colleagues [@Islami_2018]. In this study, Islami and colleagues determined that 19% of all cancers cases and roughly 29% of all cancers deaths can be attributed to cigarette smoking [@Islami_2018]. To look beyond known cancer risk factors like cigarette smoking, new cancer risk prediction models will need to detect small, but meaningful effects amid a sea of other variables.

As part of the effort to tackle this challenge, we analyzed data from Third National Health and Nutrition Examination Survey (NHANES III) [@nhanes_1994] dataset and the accompanying National Death Index (NDI). The first goal of the analysis was to explore the available NHANES data and identify potential variables of interest for cancer mortality risk prediction. The second goal was to define an approach for variable selection for cancer risk prediction models. NHANES III is different from many other studies, in that instead of randomly sampling, NHANES utilizes a complex design that employs probability-based sampling in multiple stages [@nhanes_1994]. 

While the current work focuses solely on NHANES, the data exploration and variable selection methods described herein can potentially be applied beyond NHANES to other studies that have different designs. For example, the Atherosclerosis Risk in Communities (ARIC) study [@ARIC_1989] and the Framingham Heart Study (FHS) [@Mahmood_2014] are, like NHANES, large cohort studies that do not focus on cancer, but include relevant cancer outcomes as part of rich, multidimensional datasets. In fact, the ARIC [@Joshu_2017], NHANES [@Freedman_2010], and FHS [@Kreger_1991] datasets have already proven useful for cancer research. In addition to expanding the methodology to other studies, future work on this project will include the creation of a software package that encapsulates all of the relevant code and a graphical user interface that facilitates data exploration, model parameter modification and variable selection.

## Methods

NHANES III data and documentation are available on the [Centers for Disease Control (CDC) - National Center for Health Statistics (NCHS) website](https://wwwn.cdc.gov/nchs/nhanes/nhanes3/DataFiles.aspx). The linked mortality data are available separately on the [National Death Index (NDI) website](). We processed the Interview, Medical Examination, and Laboratory, and Mortality data using the [SAS code provided by NCHS](https://wwwn.cdc.gov/nchs/nhanes/nhanes3/DataFiles.aspx), SAS University Edition version `9.04.01M5P09132017` on a Jupyter Notebook [@Kluyver_2016; @Perez_2007] server version `5.1.0` running with Python version `3.5.1` [@python_2003] on the Linux [@Torvalds_2001] operating system version `Red Hat 4.4.7-16` (with GNU Compiler Collection version `4.4.7 20120313`).

We modified the SAS code to save the data as comma-separated-value (`.csv`) files, which are available on [FigShare](). The SAS code files (`.sas`) and analogous Jupyter Notebook files (`.ipynb`) are available on [GitHub](). We then read the `.csv` files into open-source R software [@Rcore_2018] version 3.5 using the `readr` R package [@readr_2017]. R has a vibrant community and a rich ecosystem of software packages. All of the software packages used in this work can be accessed from the Comprehensive R Archive Network (CRAN) [@Hornik_2017] or from GitHub [@Vuorre_2018] using the `devtools` package [@devtools_2018].

Next, we used the `dplyr` R package [@dplyr_2017] to 1) remove all NHANES participant identifiers (`SEQN`) without cause of death (`UCOD_LEADING`) or follow-up time from interview (`PERMTH_INT`) variables, 2) create a cancer mortality variable based on whether the cause of death was "Malignant neoplasms (`C00-C97`)", 3) and join all four datasets together by the participant identifier variable. From the combined dataset, we removed baseline cancer cases (using the interview variables `HAC1N` and `HAC1O`), participants that were missing the relevant NHANES sampling variables (`SDDPSU6`, `SDSTRA6`, and `WTPFQX6`), variables with a time origin other than the date of interview (e.g. `PERMTH_EXM` ), unnecessary NHANES sampling variables, and variables that were based on or similar to the main age variable (such as the age in months, `HSAITMOR`). To create the final processed dataset, we also removed highly correlated variables using the `caret` R package.

Methods to analyze complex survey data using SAS, SPSS, STATA, SUDAAN, [@Siller_2006] and R [@Lumley_2004; @survey_2017] software have been described. From the final dataset, we randomly selected 1 to 50 predictor variables and trained Cox Proportional Hazards models with the `survey` R package [@Lumley_2004; @survey_2017], which allows for the analysis of complex survey design data using R [@Lumley_2011]. In half of the models, we applied ridge penalties [@Hoerl_1970] to the predictors variables using the `survival` R Package [@Therneau_2000; @survival_2015]. In addition to the predictor variables, the models also included 1) a "survival object" [@Therneau_2000; @survival_2015] created from the event (cancer mortality) and follow-up time variables and 2) a "design object" [@survey_2017] created from the Primary Sampling Unit (`SDDPSU6`), Stratification (`SDSTRA6`) and Weight (`WTPFQX6`) NHANES sampling variables^[The [National Center for Health Statistics (NCHS)](https://www.cdc.gov/nchs/tutorials/NHANES/SurveyDesign/SampleDesign/intro_iii.htm) recommends the application of the provided sampling design variables and sampling weights in all NHANES analyses.].

We then calculated statistics describing the models and the variables they contained and saved these statistics as `.rds` files using the `readr` package [@readr_2017]. We automated the modeling and statistical analyses using the `purrr` R package [@purrr_2017] and GNU Make [@Mecklenburg_2004]. Specifically, the model statistics collected were concordance [@Bozdogan_1987] and Akaike Information Criterion (AIC) [@Gonen_2005] values, while the variable statistics were p-values, hazard ratios, and hazard ratio confidence intervals. We unpacked the model and variable data using the `tidyr` R package [@tidyr_2018].

Next, we selected 3 potential confounder variables representing age (`HSAGEIR`) ethnicity (`DMAETHNR`), biological sex (`HSSEX`) and repeated the modeling and statistical analysis process described above. For the final modeling run, we chose an additional 5 variables (`HAB1`, `HAR1`, `HAQ1`, `HAT2`, and `HAT10`) that appeared with high frequency as highly significant (p-value < 10^-10^) variables in the models we trained earlier. We joined all of the model and variable statistics together, standardized column names using the `stringr` [@stringr_2018] R package, and reordered the variable names according to their counts using the `forcats` [@forcats_2018] R package. To make the final figures, the concordance and AIC values (Figure 1), p-values and hazard ratios (Figure 2) and the number of times each variable appeared in the models (Figure 3) were plotted using the `ggplot2` R package [@gglot2_2009].

## Results

We present the data from thousands of Cox Proportional Hazards models (n = 3789) we trained on NHANES III data in three iterative steps. The models from the first iteration (Group 1) were fully randomized in terms of the predictor variables that were included, while the next two iterations consisted of models that started with 3 and 8 non-randomized variables, respectively, before the addition of randomized variables. The 3 variables included in the second and third iteration were age, sex, and ethnicity, whereas the final iteration contained an additional 5 variables, which appeared frequently as highly significant (p < 10^-10^) variables in the previous iterations. In all case, the models contained up to 50 predictor variables. We applied ridge penalties [@Hoerl_1970], also known as L2 regularization [@Ng_2004], to half of the models from all three iterations.

The Akaike Information Criterion (AIC) [@Gonen_2005] and concordance values [@Bozdogan_1987] for all models are plotted in Figure 1. The models from the third iteration (Group 3; pink) had highest concordance values overall, indicating that the addition of the 8 non-randomized predictor variables led to higher discriminatory power between low and high-risk individuals. The gains in concordance seem to be largely due to the addition of the age, sex, and ethnicity variables as the concordance values we obtained from the second and third iterations were similar. Interestingly, the range of AIC values was roughly the same in all three groups of models, which suggests that AIC by itself is insufficient to distinguish between models.

The addition of AIC serves to provide a balance of goodness-of-fit and model complexity, because concordance, unlike AIC, does not take into account the complexity of a model. As follows, larger models tended to have higher concordance values, but also higher AIC values, while ridge penalization controls this increase in AIC as models become larger. The relationship between model size and concordance appears to plateau as concordance increases, which suggests that the models are reaching the limit of what is possible with the available 243 variables. Though there is almost certainly another combination of variables that would lead to further improvements in concordance, our approach allowed us to generate a series of models that perform well without the need to test every possible combination of the variables.

Surveying the landscape of variables in Figure 2.

We analyzed the descriptions of NHANES variables provided by NCHS and selected 3 variables to include in all future models. We then compared variables that appeared most frequently in the Cox models with high significance (p<10^-10^) and selected 5 high-frequency, highly significant variables that we used to train a new group of models with fewer randomized variables. These models consistently outperformed the fully randomized models in terms of concordance while displaying the roughly same range of AIC values.
When focusing solely on highly significant (p < 10^-10^) variables,

![Cox Proportional Hazards models (n=3789) with (triangle) and without (circle) ridge penalties on 1 to 48 variables, split into quadrants based on Concordance (y-axis) and AIC (x-axis) values. Each point in Figure 1 represents a Cox Proportional Hazards model. The size of the point is relative to the number of variables in the model it represents, while the shape corresponds to whether ridge penalties were applied (triangle) or not (circle). The color of points in Figure 1 shows whether the models had 5 constant predictor variables in addition to 1 to 45 random variables (Group 2; pink) or 1 to 50 randomized variables (Group 1). The models in Group 1 were further color coded by quadrants: high-concordance and low-AIC (Group 1A; salmon), high-concordance and high-AIC (Group 1B; gold), low-concordance and low-AIC (Group 1C; green), low-concordance and high-AIC (Group 1D; blue).](img/1-quad-final.pdf){width=100%}

![Significance (y-axis) and Hazard Ratios (x-axis) of all variables, labeled with the quadrants of the 960 Cox models as in Figure 1](img/2-volcano-final.pdf){width=100%}

![Variables that appeared most frequently, labeled with the quadrants of the 960 Cox models as in Figures 1 and 2](img/3-varbar-final.pdf){width=100%}

## Discussion

Exploring all of possible combinations of variables, known as best subset selection, would be computationally intensive and time consuming task. 
In addition to being computationally intensive and time consuming, best subset selection methods typically use a single metric to assess  
The work described here constitutes an exploratory analysis of the NHANES III dataset that employs an iterative strategy to generation of cancer risk prediction models. In this approach, a large number of models are generated randomly to inform variable selection and guide training of models in future iterations. In addition to providing insight into cancer risk factors measured in the NHANES III dataset we hope to develop a general methodology that can be applied to large, high-dimensional cohort study data.
