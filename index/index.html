<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>index.utf8</title>
  <meta name="description" content="<div class="line-block">Exploratory Analysis of Factors Associated with Cancer Mortality<br />
in the National Health and Nutrition Examination Survey Dataset</div>">
  <meta name="generator" content="bookdown 0.7.8 and GitBook 2.6.7">

  <meta property="og:title" content="index.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="index.utf8" />
  
  
  

<meta name="author" content="Martin Skarzynski">


<meta name="date" content="2018-05-02">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">


      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><div class="line-block">Exploratory Analysis of Factors Associated with Cancer Mortality<br />
in the National Health and Nutrition Examination Survey Dataset</div></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title"><div class="line-block">Exploratory Analysis of Factors Associated with Cancer Mortality<br />
in the National Health and Nutrition Examination Survey Dataset</div></h1>
<p class="author"><em>Martin Skarzynski</em></p>
<p class="date"><em>May 2, 2018</em></p>
</div>
<!--
Above is the YAML (YAML Ain't Markup Language) header that includes a lot of metadata used to produce the document.  Be careful with spacing in this header!

If you'd prefer to not include a Dedication, for example, simply delete lines 17 and 18 above or add a # before them to comment them out.  If you have other LaTeX packages you would like to include, delete the # before header-includes and list the packages after hyphens on new lines.

If you'd like to include a comment that won't be produced in your resulting file enclose it in a block like this.
-->
<!--
If you receive a duplicate label error after knitting, make sure to delete the index.Rmd file and then knit again.
-->
<!-- You'll need to include the order that you'd like Rmd files to appear in the _bookdown.yml file for
PDF files and also delete the # before rmd_files: there.  You'll want to not include 00(two-hyphens)prelim.Rmd
and 00-abstract.Rmd since they are handled in the YAML above differently for the PDF version.
-->
<!-- The {.unnumbered} option here means that the introduction will be "Chapter 0." You can also use {-} for no numbers
on chapters.
-->
<div id="introduction" class="section level2 unnumbered">
<h2>Introduction</h2>
<p>Cancer susceptibility is influenced by modifiable and non-modifiable factors. Modifiable cancer risk factors include body mass index (BMI) and cigarette use, whereas non-modifiable factors include age, sex, race/ethnicity, single nucleotide polymorphisms (SNPs), and family history of disease. According to a 2018 study by Islami and colleagues <span class="citation">[1]</span>, modifiable risk factors are responsible for 42% of all cancer cases and 45% of all cancer deaths. This finding suggests that cancer prevention strategies which target modifiable risk factors have the potential to almost halve cancer incidence and mortality in the United States. A near two-fold reduction in cancer cases and deaths may seem far-fetched, but cancer incidence and mortality in United Status have been declining by ~1.5% every year from 2009-2014 and 2001-2015, respectively <span class="citation">[2]</span>. Taken together, these data indicate that while tremendous progress has been made, there is still great potential for cancer prevention approaches to decrease cancer incidence and mortality.</p>
<p>The scale of cancer burden in the United States is staggering. Siegel and colleagues estimate that in 2018 there will be 1.7 million newly diagnosed cancer cases and roughly 600 thousand cancer deaths <span class="citation">[2]</span>. Cancer risk prediction models can help policymakers and cancer prevention practitioners develop more effective interventions and to channel limited resources towards people at the greatest risk. To achieve the best performance, cancer risk prediction models must include both modifiable and non-modifiable risk factors. For example, a 2016 study by Maas and colleagues <span class="citation">[3]</span> demonstrated that cancer risk prediction models based on known epidemiologic risk factors can provide better risk stratification when genetic information such as SNPs are included.</p>
<p>The challenge of cancer risk prediction is complex and will require cancer-type specific strategies that integrate multiple types of data and explore various modeling methods. In addition to deepening our understanding of known cancer risk factors, it is imperative to identify new factors that may only be meaningful in the larger context of contributors to cancer risk. This larger context includes the collection of genetic inheritance, called the genome, and the myriad exposures that individuals experience during their lives, known as the exposome <span class="citation">[4]</span>.</p>
<p>Some genetic factors and environmental exposures may be very strongly linked to cancer. Examples of well-described genetic and environmental cancer risk factors include TP53 gene mutation in Li-Fraumeni Syndrome and asbestos inhalation in mesothelioma, respectively. One of the strongest cancer risk factors is cigarette smoking. In fact, smoking was the strongest modifiable risk factor in the 2018 study by Islami and colleagues <span class="citation">[1]</span>. In this study, Islami and colleagues determined that 19% of all cancers cases and roughly 29% of all cancers deaths can be attributed to cigarette smoking <span class="citation">[1]</span>. To look beyond known cancer risk factors like cigarette smoking, new cancer risk prediction models will need to detect small, but meaningful effects amid a sea of other variables.</p>
<p>As part of the effort to tackle this challenge, we analyzed data from <a href="https://wwwn.cdc.gov/nchs/nhanes/nhanes3/DataFiles.aspx">Third National Health and Nutrition Examination Survey (NHANES III)</a> <span class="citation">[5]</span> and the accompanying <a href="https://www.cdc.gov/nchs/data-linkage/mortality-public.htm">National Death Index (NDI) Public-Use Linked Mortality Files</a>. The first goal of our analysis was to explore the available NHANES III data and identify potential variables of interest for cancer mortality risk prediction. The second goal was to define an approach for variable selection for cancer risk prediction models.</p>
<p>While the current work focuses solely on NHANES III, the data exploration and variable selection methods described here can potentially be applied to other studies. For example, the Atherosclerosis Risk in Communities (ARIC) study <span class="citation">[6]</span> and the Framingham Heart Study (FHS) <span class="citation">[7]</span> are, like NHANES, large cohort studies that do not focus on cancer, but include relevant cancer outcomes as part of rich, multidimensional datasets. In fact, the ARIC <span class="citation">[8]</span>, NHANES <span class="citation">[9]</span>, and FHS <span class="citation">[10]</span> datasets have already proven useful for cancer research.</p>
</div>
<div id="methods" class="section level2 unnumbered">
<h2>Methods</h2>
<p>The Third National Health and Nutrition Examination Survey (NHANES III) collected data on 33,994 participants aged 2 months and older from 1988 to 1994 in the United States. The data, which include Interview, Medical Examination, and Laboratory components, were collected and linked with Mortality data from NDI death certificate records by the National Center for Health Statistics (NCHS) of the Centers for Disease Control and Prevention (CDC). From the initial pool of participants, we selected 16,404 adult (<span class="math inline">\(age \geq 18\)</span>) participants who were cancer-free at baseline and who had no missing values for follow-up time since interview, NDI mortality, primary sampling units (PSU), stratification, and sampling weight variables.</p>
<p>The initial publicly available dataset contained 3,544 exposures from the Interview, Medical Examination, Laboratory, and Mortality components. After removing variables that were non-numeric, missing any values, only had one unique value, or had correlation to another variable greater than 0.9, we obtained the final set of 243 exposures. The analysis described here did not involve multiple imputation nor utilize the NHANES III Multiply Imputed Data Set. Among the 16,404 participants, there were 964 cancer deaths and 280,891 total years of follow-up since the initial Interview data were collected. The cancer death and follow-up time variables were used as the outcome (survival) in Cox proportional hazards regression analysis <span class="citation">[11]</span>.</p>
<p>NHANES III data and documentation are available on the <a href="https://wwwn.cdc.gov/nchs/nhanes/nhanes3/DataFiles.aspx">Centers for Disease Control (CDC) - National Center for Health Statistics (NCHS) website</a>. The National Death Index (NDI) linked mortality data are available separately on the <a href="https://www.cdc.gov/nchs/data-linkage/mortality-public.htm">Public-Use Linked Mortality Files webpage</a>. We processed the Interview, Medical Examination, and Laboratory, and Mortality data using the <a href="https://wwwn.cdc.gov/nchs/nhanes/nhanes3/DataFiles.aspx">SAS code provided by NCHS</a>, SAS University Edition version <code>9.04.01M5P09132017</code> on a Jupyter Notebook <span class="citation">[12, 13]</span> server version <code>5.1.0</code> running with Python version <code>3.5.1</code> <span class="citation">[14]</span> on the Linux <span class="citation">[15]</span> operating system version <code>Red Hat 4.4.7-16</code> (with GNU Compiler Collection version <code>4.4.7 20120313</code>).</p>
<p>We modified the SAS code to save the data as comma-separated-value (<code>.csv</code>) files, which are available on <a href="https://figshare.com/articles/adult_csv/6210263">FigShare</a>. The SAS code files (<code>.sas</code>) and analogous Jupyter Notebook files (<code>.ipynb</code>) are available on <a href="https://github.com/marskar/nhanes">GitHub</a>. We then read the <code>.csv</code> files into open-source R software <span class="citation">[16]</span> version <code>3.5</code> using the <code>readr</code> R package <span class="citation">[17]</span>. R has a vibrant community and a rich ecosystem of software packages. All of the software packages used in this work can be accessed from the Comprehensive R Archive Network (CRAN) <span class="citation">[18]</span> or from GitHub <span class="citation">[19]</span> using the <code>devtools</code> package <span class="citation">[20]</span>.</p>
<p>Next, we used the <code>dplyr</code> R package <span class="citation">[21]</span> to 1) remove all NHANES participant identifiers (<code>SEQN</code>) without cause of death (<code>UCOD_LEADING</code>) or follow-up time from interview (<code>PERMTH_INT</code>) variables, 2) create a cancer mortality variable based on whether the cause of death was “Malignant neoplasms (<code>C00-C97</code>)”, and 3) join all four datasets together by the participant identifier variable. From the combined dataset, we removed baseline cancer cases (using the interview variables <code>HAC1N</code> and <code>HAC1O</code>), participants that were missing the relevant NHANES sampling variables (<code>SDDPSU6</code>, <code>SDSTRA6</code>, and <code>WTPFQX6</code>), variables with a time origin other than the date of interview (e.g. <code>PERMTH_EXM</code> ), unnecessary NHANES sampling variables, and variables that were based on or similar to the main age variable (such as the age in months, <code>HSAITMOR</code>). To create the final processed dataset, we also removed highly correlated variables (<span class="math inline">\(r \geq 0.9\)</span>) using the <code>caret</code> R package.</p>
<p>NHANES III is different from many other studies, in that instead of randomly sampling, NHANES utilizes a complex design that employs probability-based sampling in multiple stages <span class="citation">[5]</span>. Methods to analyze complex survey data using SAS, SPSS, STATA, SUDAAN, <span class="citation">[22]</span> and R <span class="citation">[23, 24]</span> software have been described. From the final dataset, we randomly selected 1 to 50 predictor variables and trained Cox proportional hazards models with the <code>survey</code> R package <span class="citation">[23, 24]</span>, which allows for the analysis of complex survey design data using R <span class="citation">[25]</span>. In half of the models, we applied ridge penalties <span class="citation">[26]</span> to the predictors variables using the <code>survival</code> R Package <span class="citation">[11, 27]</span>. In addition to the predictor variables, the models also included 1) a “survival object” <span class="citation">[11, 27]</span> created from the event (cancer mortality) and follow-up time variables and 2) a “design object” <span class="citation">[24]</span> created from the Primary Sampling Unit (<code>SDDPSU6</code>), Stratification (<code>SDSTRA6</code>) and Weight (<code>WTPFQX6</code>) NHANES sampling variables<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<p>We then calculated statistics describing the models and the variables they contained and saved these statistics as <code>.rds</code> files using the <code>readr</code> package <span class="citation">[17]</span>. We automated the modeling and statistical analyses using the <code>purrr</code> R package <span class="citation">[28]</span> and GNU Make <span class="citation">[29]</span>. Specifically, the model statistics collected were concordance <span class="citation">[30]</span> and Akaike Information Criterion (AIC) <span class="citation">[31]</span> values, while the variable statistics were p-values, hazard ratios, and hazard ratio confidence intervals. We unpacked the model and variable data using the <code>tidyr</code> R package <span class="citation">[32]</span>.</p>
<p>Next, we selected 3 potential confounder variables representing age (<code>HSAGEIR</code>) race/ethnicity (<code>DMAETHNR</code>), sex (<code>HSSEX</code>) and repeated the modeling and statistical analysis process described above. For the final modeling run, we chose an additional 5 variables (<code>HAB1</code>, <code>HAR1</code>, <code>HAQ1</code>, <code>HAT2</code>, and <code>HAT10</code>) that appeared with high frequency as highly significant (p-value &lt; 10<sup>-10</sup>) variables in the models we trained earlier. We joined all of the model and variable statistics together, standardized column names using the <code>stringr</code> <span class="citation">[33]</span> R package, and reordered the variable names according to their counts using the <code>forcats</code> <span class="citation">[34]</span> R package. To make the final figures, the concordance and AIC values (Figure 1), p-values and hazard ratios (Figure 2) and the number of times each variable appeared in the models (Figure 3) were plotted using the <code>ggplot2</code> R package <span class="citation">[35]</span>.</p>
</div>
<div id="results" class="section level2 unnumbered">
<h2>Results</h2>
<p>We present the data from thousands of Cox proportional hazards models (n = 3789) we trained on NHANES III data in three iterative steps. The Akaike Information Criterion (AIC) <span class="citation">[31]</span> and concordance values <span class="citation">[30]</span> for all models are plotted in Figure 1. To better understand the models created during the first iteration, we divided the Group 1 models into 4 subgroups (1A, 1B, 1C, and 1D) based on their AIC and concordance values. The models from the first iteration (Figure 1; Groups 1A-D; green, cyan, blue, purple) were fully randomized in terms of the predictor variables that were included, while the next two iterations (Figure 1; Groups 2-3; orange, red) consisted of models that started with 3 and 8 non-randomized variables, respectively, before the addition of randomly chosen variables. The 3 variables included in both the second and third iteration were age, sex, and race/ethnicity, whereas the final iteration contained an additional 5 variables, which appeared frequently as highly significant (p &lt; 10<sup>-10</sup>) variables in the previous iterations. In all cases, the models contained up to 50 predictor variables.</p>
<p>The models from the third iteration (Figure 1; Group 3; red) had the highest concordance values overall, indicating that the addition of the 8 non-randomized predictor variables led to higher discriminatory power between low and high-risk individuals. The gains in concordance seem to be largely due to the addition of the age, sex, and race/ethnicity variables as the concordance values we obtained from the second (Figure 1; Group 2; orange) and third (Figure 1; Group 3; red) iterations were similar. Interestingly, models from the third iteration all had concordance values of 84 or higher (Figure 1; black horizontal line), while the range of AIC values was roughly the same in all three groups of models (Figure 1). This finding suggests that while concordance can differentiate between models from the three iterations, AIC by itself is unable to make this distinction.</p>
<div class="figure">
<embed src="figure/1-quad-final.pdf" style="height:60.0%" />
<p class="caption">Cancer Mortality Risk Prediction Models. Each point in the scatter plot represents a Cox proportional hazards model (n = 3789). The sizes of the points are relative to the number of variables (maximum = 50) in each the model, while the shapes correspond to whether ridge penalties were applied (triangle) or not (circle). The colors of points distinguish between models that had 0 (Groups 1A-D; green, cyan, blue, purple), 3 (Group 2; orange) or 8 (Group 3; red) non-randomized predictor variables. Additionally, Group 1 models are further color coded by quadrants based on concordance and Akaike Information Criterion (AIC) values as follows: high-concordance and low-AIC (Group 1A; green), high-concordance and high-AIC (Group 1B; cyan), low-concordance and low-AIC (Group 1C; blue), low-concordance and high-AIC (Group 1D; purple). All Group 3 models have concordance values of 84 or higher (black horizontal line).</p>
</div>
<p>The addition of a metric like AIC is important, because it serves to balance goodness-of-fit and model simplicity. Concordance, unlike AIC, does not take into account the complexity of a model. As follows, larger models tended to have higher concordance values, but also higher AIC values. We applied ridge penalties <span class="citation">[26]</span>, also known as L2 regularization <span class="citation">[36]</span>, to half of the models from all three iterations, and noted that ridge penalization controls this increase in AIC as models become larger (Figure 1). The relationship between model size and concordance appears to plateau as concordance increases (Figure 1), which suggests that the models are reaching the limit of what is possible with the available 243 variables. Though there is almost certainly another combination of variables that would lead to further improvements in concordance, our approach allowed us to generate a series of models that perform well without the need to test every possible combination of the variables.</p>
<p>To choose variables to be included as non-randomized variables, we consulted the NHANES variables descriptions available on the <a href="https://wwwn.cdc.gov/nchs/nhanes/nhanes3/DataFiles.aspx">Centers for Disease Control (CDC) - National Center for Health Statistics (NCHS) website</a> and for the third iteration in particular we only considered variables that had p-values lower than 10<sup>-10</sup> (Figure 2; black horizontal line). It would be possible to introduce a threshold for hazard ratios (Figure 2; x-axis), but this approach would tend to select models without ridge penalties. The coefficients in ridge penalized models are shrunk based on the penalty that is applied, which in this case means that ridge penalized models have hazard ratios closer to zero. While the significance and hazard ratios of variables depend on the other variables in the model, our method allows us to survey the landscape of p-values and hazard ratios of variables in the models trained (Figure 2).</p>
<div class="figure">
<embed src="figure/2-volcano-final.pdf" style="height:60.0%" />
<p class="caption">Lethal Cancer Risk Predictor Variables. Each point in the volcano plot represents a predictor variable (n = 98787) from a Cox proportional hazards model (n = 3789) trained on NHANES III data. Variables are considered to be highly significant when their negative log10 p-values (y-axis) are above 10 (black horizontal line), regardless of their log2 hazard ratios (x-axis). The shapes of points correspond to whether ridge penalties were applied (triangle) or not (circle). The colors of points describe the model each variable come from as in Figure 1.</p>
</div>
<p>The names, median hazard ratios, counts and descriptions of the ten most frequent highly significant variables are summarized in Table 1. The variable descriptions are based on the <a href="https://wwwn.cdc.gov/nchs/nhanes/nhanes3/DataFiles.aspx">documentation on the NHANES III website</a>. Each row in Table 1 represents one of the ten predictor variables that appeared most frequently as highly significant (p &lt; 10<sup>-10</sup>) variables in the Cox models (n = 3789) trained on NHANES III data. The median hazard ratio (HR) and count (n) statistics describe only highly significant variables. The variable that appeared most frequently as highly significant across all of the models was age (Figure 3; <code>HSAGEIR</code>). When focusing on the Group 1 models (Figure 3; Groups 1A-D; green, cyan, blue, purple), the most frequent highly significant variable was an interview question regarding dental health (Figure 3; <code>HAQ1</code>). The other top 10 high-frequency highly significant variables were race/ethnicity (<code>DMAETHNR</code>), lifetime consumption of more than 100 cigarettes (<code>HAR1</code>), 3 variables related to physical activity (<code>HAT2</code>, <code>HAT10</code>, <code>HAT16</code>), and 3 variables that may be associated to aging (<code>HAB7</code>, <code>HAK9</code>, and <code>HAP2</code>). Interestingly, one of the variables, “In the past 12 months, how many times were you in a nursing home?” (<code>HAB7</code>), was present as a highly significant variable only in the second and third groups.</p>
<div class="figure">
<embed src="figure/3-varbar-final.pdf" style="height:60.0%" />
<p class="caption">Highly Significant Predictor Variable Frequency. Each bar represents the number of times (x-axis) a variables (y-axis) appeared in the 3789 Cox proportional hazards models. The colors of bars correspond to the proportion of variables that orginiated from each of the four Group 1 subgroups (Groups 1A-D; green, cyan, blue, purple) and the subsequent iterations (Groups 2-3; orange, red), as in Figures 1 and 2.</p>
</div>
<table>
<caption>The Ten Most Frequent Highly Significant Variables</caption>
<colgroup>
<col width="23%" />
<col width="26%" />
<col width="13%" />
<col width="36%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Median HR</th>
<th align="left">n</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">HSAGEIR</td>
<td align="left">1.04</td>
<td align="left">2016</td>
<td align="left">Age in Years</td>
</tr>
<tr class="even">
<td align="left">HAQ1</td>
<td align="left">1.07</td>
<td align="left">1415</td>
<td align="left">How would you describe the condition of your natural teeth (excellent, very good, good, fair or poor)?</td>
</tr>
<tr class="odd">
<td align="left">HAT2</td>
<td align="left">1.50</td>
<td align="left">384</td>
<td align="left">In the past month, did you jog or run?</td>
</tr>
<tr class="even">
<td align="left">HAT16</td>
<td align="left">1.67</td>
<td align="left">256</td>
<td align="left">In the past month, did you lift weights?</td>
</tr>
<tr class="odd">
<td align="left">HAB7</td>
<td align="left">0.99</td>
<td align="left">228</td>
<td align="left">In the past 12 months, how many times were you in a nursing home?</td>
</tr>
<tr class="even">
<td align="left">DMAETHNR</td>
<td align="left">1.14</td>
<td align="left">224</td>
<td align="left">Race/Ethnicity</td>
</tr>
<tr class="odd">
<td align="left">HAK9</td>
<td align="left">1.23</td>
<td align="left">216</td>
<td align="left">How many times per night do you usually get up to urinate?</td>
</tr>
<tr class="even">
<td align="left">HAP2</td>
<td align="left">0.81</td>
<td align="left">179</td>
<td align="left">Do you use glasses, contacts, or both?</td>
</tr>
<tr class="odd">
<td align="left">HAT10</td>
<td align="left">1.43</td>
<td align="left">119</td>
<td align="left">In the past month, did you do other dancing?</td>
</tr>
<tr class="even">
<td align="left">HAR1</td>
<td align="left">0.63</td>
<td align="left">96</td>
<td align="left">Have you smoked at least 100 cigarettes during your entire life?</td>
</tr>
</tbody>
</table>
<p>The ranks of variables shown in Table 1 are determined by counts from all 3789 models, and thus are heavily influenced by the fact that some variables are included in all Group 2 (<code>HSAGEIR</code>, <code>DMAETHNR</code>, and <code>HSSEX</code>) and Group 3 (<code>HSAGEIR</code>, <code>DMAETHNR</code>, <code>HSSEX</code>, <code>HAB1</code>, <code>HAR1</code>, <code>HAQ1</code>, <code>HAT2</code>, and <code>HAT10</code>) models. Table 1 therefore serves as a summary of all three iterations of modeling and statistical analysis. Rather than selecting the variables with the lowest p-values or highest hazard ratios, we chose to follow a strategy that counts the number of times a variable’s significance crosses a p-value threshold. This type of frequency-based ranking of variables can be used to both guide future variable selection decisions and assess previous steps in the model building process.</p>
</div>
<div id="discussion" class="section level2 unnumbered">
<h2>Discussion</h2>
<p>To obtain a better understanding of how variables for cancer risk prediction models can be selected, we utilized an iterative strategy to explore the variables in the NHANES III dataset. As part of this strategy, we randomly generated a large number of Cox proportional hazards models to guide the training of new models with fewer randomly chosen variables in future iterations. This method is akin to forward subset selection <span class="citation">[37]</span> in that models are built up variable by variable, but differs in that models are not assessed with the addition of each new variable. In fact, the method we employed does not take model performance metrics into consideration when selecting variables. To inform variable selection in subsequent iterations, we instead focused on the frequency with which variables had p-values below 10<sup>-10</sup>.</p>
<p>In essence, our current approach aggregates information from across many models into a single statistic per variable. Variable selection decisions could be informed by another statistic or a combination of other statistics. For example, the significance threshold (p &lt; 10<sup>-10</sup>) we put in place was arbitrary and our method could be used with a different threshold value, a different metric or a combination of different thresholds. For example, variables could be selected based on the number of times the absolute value of their hazard ratio crosses a certain threshold. Model statistics could also be employed for thresholds as the concordance, Akaike Information Criterion (AIC) and other model performance metrics remain associated with variables throughout all steps in the process.</p>
<p>In addition to changing the variable selection threshold, the method described here could be adapted to use regularization techniques other than ridge regression <span class="citation">[26]</span> and models other than Cox proportional hazards models. In terms of regularization, survival analyses can be done with lasso <span class="citation">[38]</span> penalties or a combination of ridge and lasso penalties, which is known as Elastic Net <span class="citation">[39]</span>. As for possible modeling algorithms to explore in the future include tree-based models such as survival tree <span class="citation">[40]</span>, survival random forest models <span class="citation">[41]</span>. Tree-based models are easy to interpret and allow for the quantification of the proportion of variance explained by variables included in the model. Another statistical method called boosting, for example <code>XGBoost</code> <span class="citation">[42]</span>, can be used to compute F-scores representing the importance of each variable.</p>
<p>Regardless of the algorithms or thresholds used, the final result of our approach is a new dataset of statistics that describe models and variables across all iterations. This new dataset could be merged with text data, such as the <a href="https://wwwn.cdc.gov/nchs/nhanes/nhanes3/DataFiles.aspx">NHANES III variable descriptions provided by the National Center for Health Statistics</a>, and employ Natural Language Processing (NLP) <span class="citation">[43]</span> techniques to add further the information related to the models and variables in the dataset. For example, NLP techniques could be used to classify variables into categories, such as physical activity or nutrition, based on their descriptions. All of this information could then be combined with domain knowledge to steer the variable selection process.</p>
<p>The types of variables that were ranked highest in our present analysis (age, race/ethnicity, smoking and physical activity) are all already known to be strongly associated with cancer death. While obtaining an unsurprising result serves to confirm the validity of our method, the main objective of this work is to provide insight that will lead to the identification of new cancer risk factors. To this end, our method will have to be refined to detect variables that weakly contribute to cancer risk or whose contribution is context-specific.</p>
<p>We demonstrated the ability of our method to generate models that predict lethal cancer risk in the NHANES III dataset with high accuracy (<span class="math inline">\(concordance \geq 84\)</span>). It remains to be seen, whether our approach could be generalizable to other studies and other outcomes. NHANES III does not include cancer-type-specific mortality data, but other studies, such as the Atherosclerosis Risk in Communities study (ARIC) <span class="citation">[6, 8]</span>, may provide the opportunity to generate and assess models that predict mortality or incidence of a specific type of cancer. As a continuation of this project, we will expand the methods described here into a general methodology that can be applied beyond NHANES III to other large, high-dimensional cohort studies. In addition to generalization to other studies, future work on this project will include the creation of a software package that encapsulates all of the relevant code and a graphical user interface that facilitates data exploration, model parameter modification and variable selection.</p>
</div>
<div id="connections-to-mph-goals-analysis" class="section level2 unnumbered">
<h2>Connections to MPH Goals Analysis</h2>
<p>My Master of Public Health (MPH) experience at Johns Hopkins has been absolutely transformative. Though I started my MPH studies with a strong background in science, I had no experience with public health or population science. Similarly, while I was comfortable with R programming, I did not know the first thing about survey data, let alone how to conduct complex survey analyses in R. In my Goals Analysis Plan, I outlined my goal of broadening my horizons in three areas: 1) substantive expertise (domain knowledge), 2) statistics and mathematics, and 3) technical (programming) skills <span class="citation">[44]</span>. Looking back on the progress I made during my MPH studies, I am confident that I have achieved my goals. This Research Report Capstone Project is testament to the skills I honed and the knowledge I gained over the past year. I look forward to building upon this Capstone as I continue my career in cancer prevention research.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div>
<p>1. Islami F, Sauer AG, Miller KD, Siegel RL, Fedewa SA, Jacobs EJ, et al. Proportion and number of cancer cases and deaths attributable to potentially modifiable risk factors in the united states. CA: A Cancer Journal for Clinicians. 2018;68:31–54. doi:<a href="https://doi.org/10.3322/caac.21440">10.3322/caac.21440</a>.</p>
</div>
<div>
<p>2. Siegel RL, Miller KD, Jemal A. Cancer statistics, 2018. CA: A Cancer Journal for Clinicians. 2018;68:7–30. doi:<a href="https://doi.org/10.3322/caac.21442">10.3322/caac.21442</a>.</p>
</div>
<div>
<p>3. Maas P, Barrdahl M, Joshi AD, Auer PL, Gaudet MM, Milne RL, et al. Breast cancer risk from modifiable and nonmodifiable risk factors among white women in the united states. JAMA Oncology. 2016;2:1295. doi:<a href="https://doi.org/10.1001/jamaoncol.2016.1025">10.1001/jamaoncol.2016.1025</a>.</p>
</div>
<div>
<p>4. Wild CP. Complementing the genome with an &quot;exposome&quot;: The outstanding challenge of environmental exposure measurement in molecular epidemiology. Cancer Epidemiology Biomarkers &amp; Prevention. 2005;14:1847–50. doi:<a href="https://doi.org/10.1158/1055-9965.epi-05-0456">10.1158/1055-9965.epi-05-0456</a>.</p>
</div>
<div>
<p>5. National Center for Health Statistics (NCHS), others. Plan and operation of the third national health and nutrition examination survey, 1988-94. Series 1: Programs and collection procedures. Vital Health Statistics, Series 1. 1994;32:1–407.</p>
</div>
<div>
<p>6. The Atherosclerosis Risk In Communities (ARIC) study: Design and objectives. American Journal of Epidemiology. 1989;129:687–702. doi:<a href="https://doi.org/10.1093/oxfordjournals.aje.a115184">10.1093/oxfordjournals.aje.a115184</a>.</p>
</div>
<div>
<p>7. Mahmood SS, Levy D, Vasan RS, Wang TJ. The Framingham Heart Study and the epidemiology of cardiovascular disease: A historical perspective. The Lancet. 2014;383:999–1008. doi:<a href="https://doi.org/10.1016/S0140-6736(13)61752-3">10.1016/S0140-6736(13)61752-3</a>.</p>
</div>
<div>
<p>8. Joshu CE, Barber JR, Coresh J, Couper DJ, Mosley TH, Vitolins MZ, et al. Enhancing the infrastructure of the Atherosclerosis Risk in Communities (ARIC) study for cancer epidemiology research: ARIC cancer. Cancer Epidemiology Biomarkers &amp; Prevention. 2017;27:295–305. doi:<a href="https://doi.org/10.1158/1055-9965.epi-17-0696">10.1158/1055-9965.epi-17-0696</a>.</p>
</div>
<div>
<p>9. Freedman DM, Looker AC, Abnet CC, Linet MS, Graubard BI. Serum 25-Hydroxyvitamin D and Cancer Mortality in the NHANES III Study (1988–2006). Cancer Research. 2010;70:8587–97. doi:<a href="https://doi.org/10.1158/0008-5472.CAN-10-1420">10.1158/0008-5472.CAN-10-1420</a>.</p>
</div>
<div>
<p>10. Kreger BE, Splansky GL, Schatzkin A. The cancer experience in the framingham heart study cohort. Cancer. 1991;67:1–6. doi:<a href="https://doi.org/10.1002/1097-0142(19910101)67:1&lt;1::AID-CNCR2820670102&gt;3.0.CO;2-W">10.1002/1097-0142(19910101)67:1&lt;1::AID-CNCR2820670102&gt;3.0.CO;2-W</a>.</p>
</div>
<div>
<p>11. Terry M. Therneau, Patricia M. Grambsch. Modeling survival data: Extending the Cox model. New York: Springer; 2000.</p>
</div>
<div>
<p>12. Kluyver T, Ragan-Kelley B, Pérez F, Granger BE, Bussonnier M, Frederic J, et al. Jupyter notebooks - A publishing format for reproducible computational workflows. In: ELPUB. 2016. pp. 87–90.</p>
</div>
<div>
<p>13. Pérez F, Granger BE. IPython: A System for Interactive Scientific Computing. Computing in Science &amp; Engineering. 2007;9:21–9.</p>
</div>
<div>
<p>14. Van Rossum G, Drake FL. Python language reference manual. Network Theory; 2003.</p>
</div>
<div>
<p>15. Torvalds L, Diamond D. Just for fun: The story of an accidental revolutionary. Harper Business; 2001.</p>
</div>
<div>
<p>16. R Core Team. R: A language and environment for statistical computing. Vienna, Austria: R Foundation for Statistical Computing; 2018. <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a>.</p>
</div>
<div>
<p>17. Wickham H, Hester J, Francois R. Readr: Read rectangular text data. 2017. <a href="https://CRAN.R-project.org/package=readr" class="uri">https://CRAN.R-project.org/package=readr</a>.</p>
</div>
<div>
<p>18. Hornik K. R FAQ. 2017. <a href="https://CRAN.R-project.org/doc/FAQ/R-FAQ.html" class="uri">https://CRAN.R-project.org/doc/FAQ/R-FAQ.html</a>.</p>
</div>
<div>
<p>19. Vuorre M, Curley JP. Curating research assets: A tutorial on the git version control system. Advances in Methods and Practices in Psychological Science. 2018;0:2515245918754826. doi:<a href="https://doi.org/10.1177/2515245918754826">10.1177/2515245918754826</a>.</p>
</div>
<div>
<p>20. Wickham H, Hester J, Chang W. Devtools: Tools to make developing R packages easier. 2018. <a href="https://CRAN.R-project.org/package=devtools" class="uri">https://CRAN.R-project.org/package=devtools</a>.</p>
</div>
<div>
<p>21. Wickham H, Francois R, Henry L, Müller K. Dplyr: A grammar of data manipulation. 2017. <a href="https://CRAN.R-project.org/package=dplyr" class="uri">https://CRAN.R-project.org/package=dplyr</a>.</p>
</div>
<div>
<p>22. Siller AB, Tompkins L. The big four: Analyzing complex sample survey data using SAS, SPSS, STATA, and SUDAAN. In: Proceedings of the thirty-first annual sas users group international conference. SAS Institute Inc; 2006. pp. 26–9.</p>
</div>
<div>
<p>23. Lumley T. Analysis of complex survey samples. Journal of Statistical Software. 2004;9:1–19.</p>
</div>
<div>
<p>24. Lumley T. Survey: Analysis of complex survey samples. 2017. <a href="https://CRAN.R-project.org/package=survey" class="uri">https://CRAN.R-project.org/package=survey</a>.</p>
</div>
<div>
<p>25. Lumley T. Complex surveys: A guide to analysis using R. John Wiley &amp; Sons; 2011.</p>
</div>
<div>
<p>26. Hoerl AE, Kennard RW. Ridge regression: Biased estimation for nonorthogonal problems. Technometrics. 1970;12:55. doi:<a href="https://doi.org/10.2307/1267351">10.2307/1267351</a>.</p>
</div>
<div>
<p>27. Therneau TM. A package for survival analysis in s. 2015. <a href="https://CRAN.R-project.org/package=survival" class="uri">https://CRAN.R-project.org/package=survival</a>.</p>
</div>
<div>
<p>28. Henry L, Wickham H. Purrr: Functional programming tools. 2017. <a href="https://CRAN.R-project.org/package=purrr" class="uri">https://CRAN.R-project.org/package=purrr</a>.</p>
</div>
<div>
<p>29. Mecklenburg R. Managing projects with GNU make: The power of GNU make for building anything. &quot;O’Reilly Media, Inc.&quot;; 2004.</p>
</div>
<div>
<p>30. Bozdogan H. Model selection and Akaike’s information criterion (AIC): the general theory and its analytical extensions. Psychometrika. 1987;52:345–70.</p>
</div>
<div>
<p>31. Gönen M, Heller G. Concordance probability and discriminatory power in proportional hazards regression. Biometrika. 2005;92:965–70.</p>
</div>
<div>
<p>32. Wickham H, Henry L. Tidyr: Easily tidy data with ’spread()’ and ’gather()’ f unctions. 2018. <a href="https://CRAN.R-project.org/package=tidyr" class="uri">https://CRAN.R-project.org/package=tidyr</a>.</p>
</div>
<div>
<p>33. Wickham H. Stringr: Simple, consistent wrappers for common string o perations. 2018. <a href="https://CRAN.R-project.org/package=stringr" class="uri">https://CRAN.R-project.org/package=stringr</a>.</p>
</div>
<div>
<p>34. Wickham H. Forcats: Tools for working with categorical variables (f actors). 2018. <a href="https://CRAN.R-project.org/package=forcats" class="uri">https://CRAN.R-project.org/package=forcats</a>.</p>
</div>
<div>
<p>35. Wickham H. Ggplot2: Elegant graphics for data analysis. Springer-Verlag New York; 2009. <a href="http://ggplot2.org" class="uri">http://ggplot2.org</a>.</p>
</div>
<div>
<p>36. Ng AY. Feature selection, l1 vs. L2 regularization, and rotational invariance. In: Proceedings of the twenty-first international conference on machine learning. ACM; 2004. p. 78.</p>
</div>
<div>
<p>37. Kohavi R, John GH. Wrappers for feature subset selection. Artificial intelligence. 1997;97:273–324.</p>
</div>
<div>
<p>38. Tibshirani R. The lasso method for variable selection in the Cox model. Statistics in medicine. 1997;16:385–95.</p>
</div>
<div>
<p>39. Zou H, Hastie T. Regularization and variable selection via the elastic net. Journal of the Royal Statistical Society: Series B (Statistical Methodology). 2005;67:301–20.</p>
</div>
<div>
<p>40. Therneau T, Atkinson B, Ripley B. Rpart: Recursive partitioning and regression trees. 2017. <a href="https://CRAN.R-project.org/package=rpart" class="uri">https://CRAN.R-project.org/package=rpart</a>.</p>
</div>
<div>
<p>41. Ishwaran H, Kogalur UB, Blackstone EH, Lauer MS. Random survival forests. The Annals of Applied Statistics. 2008;2:841–60. doi:<a href="https://doi.org/10.1214/08-aoas169">10.1214/08-aoas169</a>.</p>
</div>
<div>
<p>42. Chen T, Guestrin C. XGBoost. In: Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining - KDD 16. ACM Press; 2016. doi:<a href="https://doi.org/10.1145/2939672.2939785">10.1145/2939672.2939785</a>.</p>
</div>
<div>
<p>43. Chowdhury GG. Natural language processing. Annual review of information science and technology. 2003;37:51–89.</p>
</div>
<div>
<p>44. Conway D. The data science venn diagram. 2010. <a href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram" class="uri">http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram</a>.</p>
</div>
</div>
</div>






<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>The <a href="https://www.cdc.gov/nchs/tutorials/NHANES/SurveyDesign/SampleDesign/intro_iii.htm">National Center for Health Statistics (NCHS)</a> recommends the application of the provided sampling design variables and sampling weights in all NHANES analyses.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
